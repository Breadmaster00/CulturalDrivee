import pandas as pd
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import os
import warnings
warnings.filterwarnings('ignore')

def load_model_and_scaler():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Å–∫–µ–π–ª–µ—Ä–∞"""
    try:
        model = load_model('price_optimizer_nn_model.h5')
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–∫–µ–π–ª–µ—Ä
        try:
            import pickle
            with open('scaler.pkl', 'rb') as f:
                scaler = pickle.load(f)
            print("‚úÖ –°–∫–µ–π–ª–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
        except:
            print("‚ö†Ô∏è  –°–∫–µ–π–ª–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π")
            scaler = StandardScaler()
            
        return model, scaler
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return None, None

def prepare_features(df):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è"""
    processed_df = df.copy()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    if 'is_done' not in processed_df.columns:
        raise ValueError("‚ùå –î–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –Ω—É–∂–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'is_done' —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏")
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    processed_df['order_timestamp'] = pd.to_datetime(processed_df['order_timestamp'])
    processed_df['hour'] = processed_df['order_timestamp'].dt.hour
    processed_df['day_of_week'] = processed_df['order_timestamp'].dt.dayofweek
    processed_df['month'] = processed_df['order_timestamp'].dt.month
    processed_df['is_weekend'] = processed_df['day_of_week'].isin([5, 6]).astype(int)
    processed_df['is_night'] = ((processed_df['hour'] >= 23) | (processed_df['hour'] <= 6)).astype(int)
    
    # –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–µ–∑–¥–∫–∏
    processed_df['distance_km'] = processed_df['distance_in_meters'] / 1000
    processed_df['duration_min'] = processed_df['duration_in_seconds'] / 60
    processed_df['pickup_km'] = processed_df['pickup_in_meters'] / 1000
    processed_df['pickup_time_min'] = processed_df['pickup_in_seconds'] / 60
    
    # –†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏
    processed_df['speed_kmh'] = processed_df['distance_km'] / (processed_df['duration_min'] / 60 + 1e-5)
    
    # –¶–µ–Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    processed_df['price_increase'] = processed_df['price_bid_local'] - processed_df['price_start_local']
    processed_df['price_increase_pct'] = (processed_df['price_bid_local'] / processed_df['price_start_local'] - 1) * 100
    processed_df['price_per_km'] = processed_df['price_start_local'] / (processed_df['distance_km'] + 1e-5)
    
    # –ü—Ä–∏–∑–Ω–∞–∫–∏ –≤–æ–¥–∏—Ç–µ–ª—è
    processed_df['driver_experience_days'] = (pd.to_datetime(processed_df['order_timestamp']) - 
                                             pd.to_datetime(processed_df['driver_reg_date'])).dt.days
    processed_df['driver_rating'] = processed_df['driver_rating'].fillna(4.5)
    
    # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è - –ø—Ä–∏–Ω—è–ª –ª–∏ –ø–∞—Å—Å–∞–∂–∏—Ä –ø–æ–≤—ã—à–µ–Ω–Ω—É—é —Ü–µ–Ω—É
    processed_df['target'] = ((processed_df['is_done'] == 1) & 
                             (processed_df['price_bid_local'] > processed_df['price_start_local'])).astype(int)
    
    # –¢–û–ß–ù–û 16 –ü–†–ò–ó–ù–ê–ö–û–í
    feature_columns = [
        'hour', 'day_of_week', 'month', 'is_weekend', 'is_night',
        'distance_km', 'duration_min', 'speed_kmh', 'pickup_km', 'pickup_time_min',
        'price_start_local', 'price_bid_local', 'price_increase', 'price_increase_pct',
        'price_per_km', 'driver_rating'
    ]
    
    # –°–æ–∑–¥–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏
    for col in feature_columns:
        if col not in processed_df.columns:
            processed_df[col] = 0
    
    X = processed_df[feature_columns].values.astype('float32')
    y = processed_df['target'].values
    
    return X, y, processed_df

def fine_tune_model(model, X, y, scaler, epochs=10, batch_size=32):
    """–î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    print("üéØ –ù–∞—á–∏–Ω–∞–µ–º –¥–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    X_scaled = scaler.transform(X)
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/validation
    X_train, X_val, y_train, y_val = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"üìä –î–∞–Ω–Ω—ã–µ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è:")
    print(f"   –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape[0]} –∑–∞–ø–∏—Å–µ–π")
    print(f"   –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_val.shape[0]} –∑–∞–ø–∏—Å–µ–π")
    print(f"   –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {y.sum()} ({y.mean():.1%})")
    
    # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —Å –º–µ–Ω—å—à–∏–º learning rate –¥–ª—è —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    model.compile(
        optimizer=Adam(learning_rate=0.0001),  # –ú–µ–Ω—å—à–µ LR –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
        loss='binary_crossentropy',
        metrics=['accuracy', 'precision', 'recall']
    )
    
    # –î–æ–æ–±—É—á–µ–Ω–∏–µ
    history = model.fit(
        X_train, y_train,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(X_val, y_val),
        verbose=1
    )
    
    # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    train_loss, train_acc, train_precision, train_recall = model.evaluate(X_train, y_train, verbose=0)
    val_loss, val_acc, val_precision, val_recall = model.evaluate(X_val, y_val, verbose=0)
    
    print(f"\nüìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–æ–±—É—á–µ–Ω–∏—è:")
    print(f"   Train Accuracy: {train_acc:.3f}, Precision: {train_precision:.3f}, Recall: {train_recall:.3f}")
    print(f"   Val Accuracy: {val_acc:.3f}, Precision: {val_precision:.3f}, Recall: {val_recall:.3f}")
    
    return model, history

def save_updated_model(model, scaler):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ —Å–∫–µ–π–ª–µ—Ä–∞"""
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    model.save('price_optimizer_nn_model_updated.h5')
    print("‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ 'price_optimizer_nn_model_updated.h5'")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∫–µ–π–ª–µ—Ä
    import pickle
    with open('scaler_updated.pkl', 'wb') as f:
        pickle.dump(scaler, f)
    print("‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–∫–µ–π–ª–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ 'scaler_updated.pkl'")
    
    # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º)
    model.save('price_optimizer_nn_model.h5')
    with open('scaler.pkl', 'wb') as f:
        pickle.dump(scaler, f)
    print("‚úÖ –ú–æ–¥–µ–ª—å –∏ —Å–∫–µ–π–ª–µ—Ä —Ç–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–æ–±—É—á–µ–Ω–∏—è"""
    print("üîÑ –ó–ê–ü–£–°–ö –ü–†–û–¶–ï–°–°–ê –î–û–û–ë–£–ß–ï–ù–ò–Ø –ú–û–î–ï–õ–ò")
    print("=" * 50)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Å–∫–µ–π–ª–µ—Ä–∞
    model, scaler = load_model_and_scaler()
    if model is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è")
        return
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
    try:
        new_data_file = 'train.csv'  # –§–∞–π–ª —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        df = pd.read_csv(new_data_file)
        print(f"‚úÖ –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(df)} –∑–∞–ø–∏—Å–µ–π")
    except FileNotFoundError:
        print(f"‚ùå –§–∞–π–ª —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ '{new_data_file}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        print("üí° –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª 'train.csv' —Å –∫–æ–ª–æ–Ω–∫–æ–π 'is_done'")
        return
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    try:
        X, y, processed_df = prepare_features(df)
        print(f"‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã: {X.shape}")
        
        # –û–±—É—á–µ–Ω–∏–µ —Å–∫–µ–π–ª–µ—Ä–∞ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ)
        if not hasattr(scaler, 'n_features_in_'):
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            print("‚úÖ –°–∫–µ–π–ª–µ—Ä –æ–±—É—á–µ–Ω –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        else:
            # –ß–∞—Å—Ç–∏—á–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∫–µ–π–ª–µ—Ä–∞
            scaler.partial_fit(X)
            print("‚úÖ –°–∫–µ–π–ª–µ—Ä –æ–±–Ω–æ–≤–ª–µ–Ω –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return
    
    # –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    try:
        updated_model, history = fine_tune_model(model, X, y, scaler, epochs=15, batch_size=32)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        save_updated_model(updated_model, scaler)
        
        print(f"\nüéâ –î–û–û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
        print("üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ 'price_optimizer_nn_model_updated.h5' –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è: {e}")

if __name__ == "__main__":
    main()